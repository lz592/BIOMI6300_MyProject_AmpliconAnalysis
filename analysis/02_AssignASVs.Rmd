---
title: "Assigning with DADA2"
author: "Liangzi"
date: "2025-03-07"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                       fig.align = "center",
                      # Send figures generated in this file to this folder below
                      fig.path = "../figures/02_AssignASVs/")
```

# Set up the encironment
## Set Seed
```{r set-seed}
# Set the seed for reproducibility
set.seed(238428)
# Let's make a parameter to set the number of threads 
n_threads = 20
```
#Timing of this script
```{r}
# What time did we start running this script? 
start_time <- Sys.time()
```

## Load Packages
```{r load-packages}
pacman::p_load(tidyverse, devtools, dada2, 
               patchwork, DT, install = FALSE)
```

# Load Filtered Fastq Files
```{r load-filtered-fastqs}
# Place filtered seq into a variable
filtered_fastqs_path <- "/local/workdir/lz592/MyProject/data/02_filtered_fastqs/"

# Intuition Check 
filtered_fastqs_path

# Create Forward vector 
filtered_forward_reads <- 
  list.files(filtered_fastqs_path, pattern = "1_filtered.fastq.gz",
             full.names = TRUE)
# Check 
filtered_forward_reads[1:5]

# Reverse vector
filtered_reverse_reads <- 
    list.files(filtered_fastqs_path, pattern = "2_filtered.fastq.gz",
             full.names = TRUE)  
# Check 
filtered_reverse_reads[1:5]
```

# Sample Name
```{r sample-name}
# Create vector of sample names from the filenames 
sample_names <- sapply(strsplit(basename(filtered_forward_reads), "_"), `[`,1) 

# Intuition Check 
head(sample_names)
```

# Error Modelling
```{r learn-errors}
# Forward Reads
error_forward_reads <-
  learnErrors(filtered_forward_reads, multithread = n_threads)
# Forward Error Plot
forward_error_plot <- 
  plotErrors(error_forward_reads, nominalQ = TRUE) + 
  labs(title = "Forward Reads: Error Model")

# Reverse Reads
error_reverse_reads <- 
  learnErrors(filtered_reverse_reads, multithread = n_threads)

# Reverse Error Plot
reverse_error_plot <- 
  plotErrors(error_reverse_reads, nominalQ = TRUE) + 
  labs(title = "Reverse Reads: Error Model")

# Put the two plots together
forward_error_plot + reverse_error_plot
```

# Infer ASVs
```{r infer-ASVs}
# Infer ASVs on the forward sequences
dada_forward <- 
  dada(filtered_forward_reads, 
       err = error_forward_reads,
       multithread = n_threads) 
# Take a look at the data
typeof(dada_forward)
dada_forward
length(dada_forward)

# What does it look like for each sample?  
dada_forward$`SRR12873302_1_filtered.fastq.gz`

# Reverse ASVs
dada_reverse <- dada(filtered_reverse_reads,
                     err = error_reverse_reads,
                     multithread = n_threads)
# Check data
dada_reverse[30]
```

# Merge Forward and Reverse ASVs
```{r merge-ASVs}
merged_ASVs <-
  mergePairs(dada_forward, filtered_forward_reads, 
             dada_reverse, filtered_reverse_reads,
             verbose = TRUE)

# Evaluate the data output
typeof(merged_ASVs)
length(merged_ASVs)
head(names(merged_ASVs)) # Access our current sample names

# Inspect further: Inspect the whole merger data.frame
head(merged_ASVs)

# Inspect further for each sample
#head(merged_ASVs, n = 2) # A dataframe for each sample
# We have a dataframe in each part of our list! What are in the columns? 
glimpse(merged_ASVs$`SRR12873303_1_filtered.fastq.gz`)
```

# Create Raw ASV Count Table
```{r raw-ASV-count-table}
raw_ASV_table <- makeSequenceTable(merged_ASVs)

# Check the type and dimensions of the data
dim(raw_ASV_table)
typeof(raw_ASV_table)
class(raw_ASV_table)

# Write out the file 'raw_ASV_table' to data/01_DADA2/
write.table(raw_ASV_table, file = "data/raw_ASV_counts.tsv", 
            sep = "\t", quote = FALSE, col.names = NA)
```

# Assess ASV Quality 
## What are the current ASV lengths? 
**INTERPRETATION #1:**
*What is the hypothesized ASV length for your project data set? Please insert a description here, similar to the statements above, of the expected ASV length. Please provide a clear explanation using the following, which an example is provided above: (1) sequencing strategy, (2) total length of starting amplicons, (3) the expected ASV length without the primers, (4) length expected after the filterAndTrim() step, and (5) the expected percent overlap.*

*1. The sequencing strategy*
- Paired-end (2x300bp) Illumina MiSeq Sequencing was used.
- Specifically, the V4 hypervariable region of the 16S rRNA gene was targeted for sequencing with the 515F and 907R primers.
*2. The total length of starting amplicons*
- Our primers are named after the location they bind to on the 16S gene. So:
907 - 515 = 392 bp
- The total length of the starting amplicon is 392 base pairs, with primers.
*3. What is the ASV length without primers?*
The 515F (5'-GTGCCAGCMGCCGCGG-3') primer is 16 base pairs.
The 907R (5'-CCGTCAATTCMTTTRAGTTT-3') primer is 20 base pairs.
392 - 16 - 20 = 356 bp
The expected ASV length without primers is 356 base pairs.
*4. The length expected after the filterAndTrim() step*
In my 01_QualityTrimming.Rmd, I used trimLeft = (16,20) to trim the primers sequences, removing 16 bases at the beginning of the forward read and 20 bases at the beginning of the revere read. Using truncLen = c(280, 210) to trim 20 bases at the end of the forward read and 90 bases at the end of the reverse read. Therefore, the length expected after the filterAndTrim() step is 356 bp.
*5. The expected percent overlap*
The author performed 2x300 paired-end Illumina MiSeq Sequencing. 
However, from the multiQC report, we can see that the read length is actually 301 bp.
If we have a total read length of 301 base pairs and we did not sequence our primers, then the overlap should be ~100%.

# ASV Length Stats
```{r assess-ASV-length}
# Calculate summary stats
# Longest ASV?
maxLength_ASV <- max(nchar(getSequences(raw_ASV_table)))

# Shortest ASV?
minLength_ASV <- min(nchar(getSequences(raw_ASV_table))) 

# Mean ASV length?
meanLength_ASV <- mean(nchar(getSequences(raw_ASV_table))) 

# Median ASV length?
medianLength_ASV <- median(nchar(getSequences(raw_ASV_table))) 

# Create a table to Inspect the distribution of sequence lengths of all ASVs in dataset 
table(nchar(getSequences(raw_ASV_table)))
```

### ASV Length Plot 
```{r ASV-lengths-plot}
# Inspect the distribution of sequence lengths of all ASVs in data set 
# AFTER TRIM
plot_ASVLength_raw <- 
  data.frame(Seq_Length = nchar(getSequences(raw_ASV_table))) %>%
  ggplot(aes(x = Seq_Length )) + 
  geom_histogram() + 
  # include the x-axis scales
  scale_x_continuous(limits = c(0, maxLength_ASV + 5)) + 
  labs(y = "Number of ASVs", x = "Raw ASV Length (bps)")

# Show the plot
plot_ASVLength_raw
```

**INTERPRETATION #2:**
*Does the ASV length data (table and plot above) match your hypotheses from INTERPRETATION #1? Why or why not? Please insert a description of the interpretation you draw regarding the lengths of your ASVs that you’ve inferred from the ASV length table and it’s graphical visualization above.*
As we saw in the table, the length of the ASVs is mostly ~385-389 base pairs.
The histogram also shows a strong peak around ~385-389 bp.
Interpretation:
The observed ASV lengths are longer than expected (~385-389 bp vs. Expected 356 bp).
Therefore, the ASV length data (table and plot) does not fully match my hypotheses from INTERPRETATION #1. This suggests that additional trimming may be necessary or that some sequences contain artifacts that need further filtering.
The reasons for that might be:
1) The observed ASV lengths suggest that some sequences may still contain primer remnants; 2) If overlapping regions were imperfectly merged, some reads may have retained additional bases; 3) Some of the longer ASVs could be due to chimeric sequences that were not fully removed.

**INTERPRETATION #3:**
*Taking into account INTERPRETATIONS #1 and #2, what is your suggested trimming procedure for your ASV lengths? Will you allow some variation or trim to an exact length, similar to our in class example here?*
Explicitly trim primers before filterAndTrim(); adjust truncLen values to the the expected ASV length length while allowing some variation; check the new ASV length distribution post-filtering to confirm improvements.

# Trim ASV lengths
```{r trim-ASVs}
# Subset only ASVs that are 385-389 bps long 
raw_ASV_table_trimmed <- 
  raw_ASV_table[,nchar(colnames(raw_ASV_table)) %in% 385:389]

# Inspect the distribution of sequence lengths of all ASVs in dataset 
table(nchar(getSequences(raw_ASV_table_trimmed)))

# What proportion of total ASV sequences are left in the data? 
percRetained_Trimmed <- sum(raw_ASV_table_trimmed)/sum(raw_ASV_table)
percRetained_Trimmed # Show it 

# Inspect the distribution of sequence lengths of all ASVs in dataset 
# AFTER TRIM
plot_ASVLength_trimmed <- 
  data.frame(Seq_Length = nchar(getSequences(raw_ASV_table_trimmed))) %>%
  ggplot(aes(x = Seq_Length )) + 
  geom_histogram() + 
  # include the x-axis scales
  scale_x_continuous(limits = c(0, maxLength_ASV + 5)) + 
  labs(y = "Number of ASVs", x = "Trimmed ASV Length (bps)")

# Show the plot 
plot_ASVLength_trimmed
```

# Remove Chimeras
```{r rm-chimeras, fig.width=3.5, fig.height=3}
# Remove the chimeras in the raw ASV table
noChimeras_ASV_table <- 
  removeBimeraDenovo(raw_ASV_table_trimmed, 
                     method="consensus", 
                     multithread = n_threads, 
                     verbose=TRUE)
# Check the dimensions
dim(noChimeras_ASV_table)

# What proportion is left of the sequences? 
# Chimera removal compared to trimming 
percRetained_chimerasTrimmed <- sum(noChimeras_ASV_table)/sum(raw_ASV_table_trimmed)
percRetained_chimerasTrimmed # Show it!
# Chimera removal compared to raw  
percRetained_chimerasRaw <-sum(noChimeras_ASV_table)/sum(raw_ASV_table)
percRetained_chimerasRaw # Show it!

# Plot it 
plot_ASVLength_NoChimeras <- 
  data.frame(Seq_Length_NoChim = nchar(getSequences(noChimeras_ASV_table))) %>%
  ggplot(aes(x = Seq_Length_NoChim )) + 
  geom_histogram()+ 
  # include the x-axis scales
  scale_x_continuous(limits = c(0, maxLength_ASV + 5)) + 
  labs(y = "Number of ASVs \n (Post-Chimera Removal)", 
       x = "ASV Length (bps)")

# Show the plot
plot_ASVLength_NoChimeras 
```
**INTERPRETATION #4:**
*(1) What proportion of raw ASVs were retained after trimming? (2) What proportion of the trimmed ASVs were retained after chimera removal? (3) What proportion of the total merged ASVs were retained after both trimming and chimera removal? Do you think that the ASV lengths have been trimmed appropriately? For inspiration, you are encouraged to describe the conclusions from the the ASV length plot below.*

1. 87.66% of the raw ASVs were retained after trimming.
2. 91.77% of the trimmed ASV counts were retained after chimera removal.
3. This translates to 80.45% retention of the original, raw merged ASV counts after both trimming and chimera removal.
From the ASV length plot, the expected ASV length was 356 bp after trimming. However, the observed lengths are mostly between 385-389 bp, suggesting that trimming may not have been as strict as expected. The reasons could be: Some sequences still contain primer remnants; imperfect merging may have resulted in extra bases being retained; chimeric sequences that were not fully removed could be contributing to longer ASVs. 
This suggests that further refinement in truncLen and primer removal steps may be necessary.

# Plot ASV Lengths
```{r plot-ASVLengths, fig.height=2.5, fig.width=7}
plot_ASVLength_raw + plot_ASVLength_trimmed + plot_ASVLength_NoChimeras + 
    plot_annotation(tag_levels = 'A')
```

# Track the read counts
```{r track-reads, fig.width=6, fig.height=4}
# A little function to identify number seqs 
getN <- function(x) sum(getUniques(x))

# Make the table to track the seqs 
track <- cbind(sapply(dada_forward, getN),
               sapply(dada_reverse, getN),
               sapply(merged_ASVs, getN),
               rowSums(noChimeras_ASV_table))

head(track)

# Update column names to be more informative (most are missing at the moment!)
colnames(track) <- c("denoisedF", "denoisedR", "merged", "nochim")
rownames(track) <- row.names(noChimeras_ASV_table)

# Generate a dataframe to track the reads through our DADA2 pipeline
track_counts_df <- 
  track %>%
  # make it a dataframe
  as.data.frame() %>%
  rownames_to_column(var = "sample_names")

# Now let's add a column for the number of ASVs
# First, intuition check that the samples match 
stopifnot(track_counts_df$sample_names == row.names(noChimeras_ASV_table))

# Now, let's add a new column with the number of ASVs
track_counts_df <- 
  track_counts_df %>%
  mutate(num_ASVs = rowSums(noChimeras_ASV_table > 1))

# Visualize it in table format 
DT::datatable(track_counts_df)

# Plot it!
track_counts_df %>%
  pivot_longer(denoisedF:nochim, names_to = "read_type", values_to = "num_reads") %>%
  mutate(read_type = fct_relevel(read_type, "denoisedF", "denoisedR", "merged", "nochim")) %>%
  ggplot(aes(x = read_type, y = num_reads, fill = read_type)) + 
  geom_line(aes(group = sample_names), color = "grey") + 
  geom_point(shape = 21, size = 3, alpha = 0.8) + 
  scale_fill_brewer(palette = "Spectral") + 
  labs(x = "Filtering Step", y = "Number of Sequences") + 
  theme_bw()
```

Now, let's plot the number of sequences that have been maintained in our samples using `geom_histogram()`. 
```{r numSeqsASV-plot, fig.height=2.5, fig.width=7}
plot_ReadDepth <- 
  track_counts_df %>%
  ggplot(aes(x = nochim)) + 
  geom_histogram() + 
  labs(x = "Total # of Sequences", y = "# of Samples") + 
  theme_bw()

# What is the ASV richness per sample? 
plot_ASVRichness <- 
  track_counts_df %>%
  ggplot(aes(x = num_ASVs)) + 
  geom_histogram() + 
  labs(x = "Total # of ASVs", y = "# of Samples") + 
  theme_bw()

# Now, let's look at the relationship of ASVs and Sequencing depth 
plot_ReadDepth_ASVRichness <- 
  track_counts_df %>%
  ggplot(aes(x = nochim, y = num_ASVs)) + 
  geom_point() + 
  labs(x = "Total # of Sequences", y = "# of ASVs") + 
  theme_bw()

# Show the plots together 
plot_ReadDepth + plot_ASVRichness + plot_ReadDepth_ASVRichness + 
    plot_annotation(tag_levels = 'A')
```
**INTERPRETATION #5:**
*What conclusions can you draw from each of the three individual plots above? Please note anything important that the figure might indicate regarding your project data. Are there any specific notes and considerations for later?*

The figure above consists of three plots that summarize sequencing depth, ASV richness, and their relationship after DADA2 processing of 16S rRNA gene sequencing data.

*Panel A: Read Depth after DADA2: Histogram of sequencing depth per sample (Total # of Sequences)*
•	The majority of samples have between 30,000 and 50,000 sequences, which suggests that sequencing depth is relatively high. 
•	However, there is a large number of samples with 0 sequences, indicating that some samples completely failed to retain sequences.
Implications: 
•	Poor initial sequencing quality in those samples.
•	Overly strict filtering parameters (e.g., trimming too many bases, leading to shorter-than-expected reads).
•	Issues with primer removal or merging errors.
Next steps: 
•	Investigate the failed samples—were they originally low in read count before trimming?
•	Consider adjusting trimming and filtering parameters to see if recovery is possible.

*Panel B: ASV Richness after DADA2: Histogram of ASV richness (Total # of ASVs per sample)*
•	The number of ASVs per sample follows a similar pattern to Panel A.
•	Most samples have between 100 and 400 ASVs, which seems reasonable.
•	However, some samples again show 0 ASVs, mirroring the pattern in Panel A.
Implications: 
•	If a sample has 0 sequences, it naturally has 0 ASVs.
•	A sample with sequences but no ASVs could indicate an issue with denoising or chimera removal.
Next steps: 
•	Re-examine the truncLen and filterAndTrim() settings to ensure they are not overly aggressive.
•	Consider relaxing chimera removal settings if too many sequences are getting filtered out.

*Panel C: Read Depth vs ASV Richness: Scatter plot showing the relationship between sequencing depth and ASV richness.*
•	Generally there might be a positive correlation, where samples with higher read depth tend to have more ASVs. This helps show the importance of rarefaction.
•	A few samples with very low sequence counts have nearly 0 ASVs, indicating the issue (i.e. sequencing failures, poor-quality samples, and/or negative controls) observed in Panels A and B.
Next steps: 
•	If the variation is expected (e.g., due to different sample sources), it may not be a concern.
•	If some samples have abnormally high or low ASV retention, investigate whether they were affected by sequencing quality or pipeline settings.

*Considerations for Later*
•	Investigate why some samples have 0 sequences and 0 ASVs.
•	Check filtering and trimming parameters to see if adjustments could improve retention.
•	Assess chimera removal settings—if too strict, it may be removing too many real sequences.
•	Compare diversity metrics across samples to see if sequencing bias exists.

# Assign Taxonomy 
```{r assign-tax}
# Assign up to genus level 
taxa_train <- 
  assignTaxonomy(noChimeras_ASV_table, 
                 refFasta = "/workdir/in_class_data/taxonomy/silva_nr99_v138.2_toGenus_trainset.fa.gz", 
                 multithread = n_threads)

# Add the genus/species information 
taxa_addSpecies <- 
  addSpecies(taxa_train, 
              refFasta = "/workdir/in_class_data/taxonomy/silva_v138.2_assignSpecies.fa.gz")

# Inspect the taxonomy 
glimpse(taxa_addSpecies) # Note that the rownames are the ASV sequences!
# Let's removing the ASV sequence rownames for display only
taxa_print <- taxa_addSpecies 
rownames(taxa_print) <- NULL
head(taxa_print)
#View(taxa_print)
```

# Export the Data
## 1. ASV Tables
### Structure of ASV tables
```{r structure-ASV-table}
# What's the current format of the ASV table?
head(rownames(noChimeras_ASV_table)) # Samples!
head(colnames(noChimeras_ASV_table)) # ASV Sequences

# Therefore, we need to transpose the matrix 
final_ASV_table_withSeqs <- t(noChimeras_ASV_table)

# Intuition check
head(rownames(final_ASV_table_withSeqs)) # ASV Sequences
head(colnames(final_ASV_table_withSeqs)) # Sample names
```

### Names in ASV tables
#### Fix Sample Names 
```{r SampleNames-ASV-table}
# Remember at the top of the file we created a vector of sample names 
head(sample_names)
# Let's check with the actual column names 
head(colnames(final_ASV_table_withSeqs)) # Sample names
# And then apply our sample name script to check, too
head(sapply(strsplit(colnames(final_ASV_table_withSeqs), "_"), `[`,1)) # Looks good! 

# Now, add a break in the script break if this isn't true! 
# Let's make sure the sample names match the file names in the matrix.
stopifnot(sapply(strsplit(colnames(final_ASV_table_withSeqs), "_"), `[`,1) == sample_names)

# Now, we've done some checks to prove to ourselves there will be no silent errors, 
# Let's rename! 
colnames(final_ASV_table_withSeqs) <- sample_names
head(colnames(final_ASV_table_withSeqs))
```

#### Rename ASVs
```{r prepare-ASVcount-Seqtable}
# Give headers more manageable names
# First pull the ASV sequences from the rownames
ASV_seqs <- rownames(final_ASV_table_withSeqs)
ASV_seqs[1:5]

# How many ASVs? 
num_ASVs <- dim(final_ASV_table_withSeqs)[1] # select the number of rows
num_ASVs 

# Make an empty vector the length of the number of ASVs, 
# which is where we will place the new operational ASV names 
ASV_headers <- vector(num_ASVs, mode = "character")

# Let's mae sure we have an empty vector!
ASV_headers[1:5]
length(ASV_headers) # looks good! 

# Now, let's create a vector with ASV numbers
# loop through vector and fill it in with ASV names 
for (i in 1:num_ASVs) {
  # Add leading zero to ASV name so they print in correct order.
  ASV_number <- sprintf("%04d", i)
  # Now, rename each spot in the ASV header vector as we loop through the for loop
  ASV_headers[i] <- paste(">ASV", ASV_number, sep = "_")
}

# Intuition check
ASV_headers[1:5]

# Create a new ASV table, which will have the ASV numbers as names 
# View(noChimeras_ASV_table) # To view the table
final_ASV_table <- final_ASV_table_withSeqs
glimpse(final_ASV_table)

## Replace the ASV seqs with the ASV numbers 
row.names(final_ASV_table) <- sub(">", "", ASV_headers)
final_ASV_table[1:5, 1:5]
#View(final_ASV_table) # To view the table
```

### Write the ASV Tables!
```{r write-asv-tables}
# 1. Write count table with ASV sequence names
write.table(final_ASV_table_withSeqs, 
            file = "data/ASV_table_withSeqNames.tsv", 
            sep = "\t", quote = FALSE, col.names = NA)

# 2. Write count table with ASV numbered names (e.g. ASV_1, ASV_2, etc)
write.table(final_ASV_table, 
            file = "data/ASV_table.tsv", 
            sep = "\t", quote = FALSE, col.names = NA)
```

## 2. ASV Fasta File 
### Write the ASV Fasta File
```{r write-asv-fastas}
# Let's take our asv_headers
head(ASV_headers, n = 2)
# And combine it with their sequences
head(ASV_seqs, n = 2)

# Combine in a fasta format with the cbind() function
ASV_fasta <- c(rbind(ASV_headers, ASV_seqs))
head(ASV_fasta, n = 4)

# Then, let's write it to a fasta file!
# This will be our reference later on for which seq matches which ASV
write(ASV_fasta, "data/ASVs.fasta")
```

## 3. Taxonomy Table 
### Reformat Taxonomy 
```{r reformat-tax-table}
# Inspect the taxonomy table
dim(taxa_addSpecies) # ASVs are in rows and Kingdom, Phylum, etc in Columns 
colnames(taxa_addSpecies) # Column names are Linnean Taxonomy 
head(rownames(taxa_addSpecies), n = 2) # ASV names are rownames 
class(taxa_addSpecies) # Character matrix

##### Prepare tax table 
# 1. Add the ASV sequences from the rownames to a column 
new_tax_table <- 
  taxa_addSpecies%>%
  as.data.frame() %>%
  rownames_to_column(var = "ASVseqs") 

# Intuition check 
glimpse(new_tax_table)

# IMPORTANT! Let's do our intuition check 
# This is where we ensure we don't mix up the ASV names!
stopifnot(new_tax_table$ASVseqs == rownames(final_ASV_table_withSeqs))

# Now let's add the ASV names 
rownames(new_tax_table) <- rownames(final_ASV_table)
head(new_tax_table)

### Final prep of tax table. Add new column with ASV names 
ASV_tax_table <- 
  new_tax_table %>%
  # add rownames from count table for phyloseq handoff
  mutate(ASV = rownames(final_ASV_table)) %>%
  # Reorder the columns
  dplyr::select(Kingdom, Phylum, Class, Order, Family, Genus, Species, ASV, ASVseqs)

# Assign the rownames, which is required by phyloseq
rownames(ASV_tax_table) <- ASV_tax_table$ASV

# Take a quick look
glimpse(ASV_tax_table)

# Intution check
stopifnot(ASV_tax_table$ASV == rownames(ASV_tax_table), 
          rownames(ASV_tax_table) == rownames(ASV_tax_table))
```

### Write the Taxonomy Table 
```{r write-tax-table}
# Write the table 
write.table(ASV_tax_table, 
            file = "data/ASV_taxonomy.tsv", 
            sep = "\t", quote = FALSE, col.names = NA)
```

## 4. Sample Data 
```{r save-track reads}
# And save the track_counts_df a R object, which we will merge with metadata information in the next step of the analysis in nalysis/02_Taxonomic_Assignment. 
save(track_counts_df, file = "data/track_read_counts.RData")
```

# Final info for Reproducibility 
## Check Render Time
```{r stop-time}
# Take the time now that we are at the end of the script
end_time <- Sys.time()
end_time 

# Echo the elapsed time
elapsed_time <- round((end_time - start_time), 3)
elapsed_time
```

## Session Information
```{r session-info}
# Ensure reproducibility with package version information
devtools::session_info()
```


